{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db437dfe",
   "metadata": {},
   "source": [
    "## 1. Initialize the project\n",
    "\n",
    "Create a working context (project) if not created already. Project is a placeholder for the code, function, data, and management of the data operations and workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22976efc-003a-4170-bcf0-6a33ac84e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitalhub as dh\n",
    "PROJECT_NAME = \"<YOUR_PROJECT_NAME>\"\n",
    "proj = dh.get_or_create_project(PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ac45be",
   "metadata": {},
   "source": [
    "## 2. Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b5bbf",
   "metadata": {},
   "source": [
    "This section describes the required artifacts (sentinel data, shape and map files) needed to run the elaboration function for the requested area of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e695d4f4",
   "metadata": {},
   "source": [
    "### 1- Sentinel data\n",
    "\n",
    "Please note that this function 'elaborate-flood-data' depends on Sentinel data artifacts, which must be logged in to the project context(if not already) both for ascending and descending orbits using the catalog function 'download-sentinel-data'. For more detailed information, please refer to the catalog function [download-sentinel-data](../download-sentinel-data/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5986f976",
   "metadata": {},
   "source": [
    "### 2- Shape and Map data.\n",
    "Save the necessary artifacts (shape, map files) for the required area of interest inside to the project context.  For e.g. river shape file for Trentino region can be downloaded from the open data portal link below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c808798",
   "metadata": {},
   "source": [
    "https://siat.provincia.tn.it/geonetwork/srv/ita/catalog.search#/metadata/p_TN:df06e63c-d0f3-46c9-8ec2-c25a22c50ef7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bacdbb",
   "metadata": {},
   "source": [
    "Download the zip file from link above and extract the contents inside a folder 'Rivers_TN' and log it as project artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648d95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_name='Rivers_TN'\n",
    "src_path='Rivers_TN'\n",
    "artifact_bosco = proj.log_artifact(name=artifact_name, kind=\"artifact\", source=src_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac999cd5",
   "metadata": {},
   "source": [
    "Similary, log the lakes shape file of the area of interest for e.g. the lake shape file for Trentino region can be downloadedfrom the SIAT Portal link below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf90ac2",
   "metadata": {},
   "source": [
    "https://siat.provincia.tn.it/geonetwork/srv/ita/catalog.search#/metadata/p_TN:0f1fdc33-5c71-4c6d-81e7-25eb2ab0e599"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057292d6",
   "metadata": {},
   "source": [
    " Download the zip file from link above and extract the contents of subfolder 'idrspacq' inside a new folder 'Lakes_TN' and log it as project artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daadbe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_name='Lakes_TN'\n",
    "src_path='Lakes_TN'\n",
    "artifact_bosco = proj.log_artifact(name=artifact_name, kind=\"artifact\", source=src_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382bf909",
   "metadata": {},
   "source": [
    "Log the slope shape file of your area of interest for e.g. for trentino region, slop shape file can be downloaded from the Huggingface repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f524887a",
   "metadata": {},
   "source": [
    "https://huggingface.co/datasets/lbergamasco/trentino-slope-map/blob/main/trentino_slope_map.tif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48f015",
   "metadata": {},
   "source": [
    " Download and extract the contents inside a folder 'Slopes_TN' and log it as project artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e37c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_name='Slopes_TN'\n",
    "src_path='Slopes_TN'\n",
    "artifact_bosco = proj.log_artifact(name=artifact_name, kind=\"artifact\", source=src_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e55587",
   "metadata": {},
   "source": [
    "The resulting datasets will be registered as the project artifact in the datalake under the given names ('Rivers_TN', 'Slopes_TN', 'Lakes_TN')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb435f0",
   "metadata": {},
   "source": [
    "## 3. Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa224f",
   "metadata": {},
   "source": [
    "Fetch the \"elaborate-flood-data\" operation in the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97812863",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_el = proj.get_function(\"elaborate-flood-data\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86715cf",
   "metadata": {},
   "source": [
    "As indicated, the elaboration of flood data depends on four distinct temporal Sentinel datasets collected around the flood event date:\n",
    "\n",
    "Sentinel-2: ±20 days\n",
    "\n",
    "Sentinel-1: ±7 days\n",
    "\n",
    "These temporal windows represent the default acquisition periods used by the elaborate function to detect pre- and post-flood conditions.\n",
    "\n",
    "Before running the elaborate function, you must log all four required Sentinel data artifacts, following the instructions provided in the Sentinel Data section above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e1d751",
   "metadata": {},
   "source": [
    "### Function Input Parameters\n",
    "\n",
    "As described in the README.md, the elaboration function expects a list of arguments.\n",
    "The first argument is the bash script executed when the container starts, while the subsequent arguments contain both fixed and dynamic parameters.\n",
    "\n",
    "#### Fixed Parameters\n",
    "\n",
    "The fixed parameter includes both the project artifacts names\n",
    "\n",
    "- `sentinel1_GRD_preflood`\n",
    "- `sentinel1_GRD_postflood`\n",
    "- `sentinel2_pre_flood`\n",
    "- `sentinel2_post_flood`\n",
    "- `Slopes_TN`,\n",
    "- `trentino_slope_map.tif`,\n",
    "- `Lakes_TN`\n",
    "- `idrspacq.shp`\n",
    "- `Rivers_TN`\n",
    "- `cif_pta2022_v.shp`\n",
    "\n",
    "as well as the the scenario configuration parameters like \n",
    "\n",
    "- `targetCRS`,\n",
    "- `polarization`,\n",
    "- `dem_threshold`,\n",
    "- `slope_threshold`\n",
    "- `noise_min_pixels`\n",
    "- `river_buffer_meters`\n",
    "\n",
    "The set of dynamic parameters included\n",
    "\n",
    "- `outputName`\n",
    "- `floodDate`\n",
    "- `geometry`\n",
    "\n",
    "These parameters are configured as per the area of interest for e.g. the launch for flood elaboration for flooding event of Oct 2, 2020 in Trentino region is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8be96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_el = function_el.run(\n",
    "    action=\"job\",\n",
    "    fs_group='8877',\n",
    "    resources={\n",
    "        \"cpu\": {\"requests\": \"3\", \"limits\": \"6\"},\n",
    "        \"mem\":{\"requests\": \"32Gi\", \"limits\": \"64Gi\"}\n",
    "    },\n",
    "    volumes=[{\n",
    "        \"volume_type\": \"persistent_volume_claim\",\n",
    "        \"name\": \"volume-flood\",\n",
    "        \"mount_path\": \"/app/data\",\n",
    "        \"spec\": { \"size\": \"200Gi\" }\n",
    "        }],\n",
    "    args=[\n",
    "        '/shared/launch.sh',\n",
    "        'sentinel1_GRD_preflood',\n",
    "        'sentinel1_GRD_postflood',\n",
    "        'sentinel2_pre_flood',\n",
    "        'sentinel2_post_flood',\n",
    "        'POLYGON ((10.644988646837982 45.85539621678084, 10.644988646837982 46.06780100571985, 10.991744628283294 46.06780100571985, 10.991744628283294 45.85539621678084, 10.644988646837982 45.85539621678084))',\n",
    "        'Slopes_TN', \n",
    "        'trentino_slope_map.tif',\n",
    "        'Lakes_TN',\n",
    "        'idrspacq.shp',\n",
    "        'Rivers_TN',\n",
    "        'cif_pta2022_v.shp',\n",
    "        'garda_oct_2020',\n",
    "        '2020-10-02',\n",
    "        'EPSG:25832',\n",
    "        \"['VV','VH']\",\n",
    "        '700',\n",
    "        '7',\n",
    "        '15',\n",
    "        '2',\n",
    "        'val di fassa'\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f48e36",
   "metadata": {},
   "source": [
    "As indicated in the funciton README, the pixel based analysis performed in the elaboration steps are computation heavy. The best possible performance matrix is more or less around the configuration indicated in the step above. The amount of sentinal data can vary. A safe limit volume of 100Gi is specified as persistent volume claim to ensure significant data space. The function takes around 40 mins to complete with 16 CPUs and 64GB Ram for a flood event indicated above. The output GeoTIFF raster file flood_detection_layer.tif is saved in the project context as an artifact zip file (garda_oct_2020) as configured output name."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
