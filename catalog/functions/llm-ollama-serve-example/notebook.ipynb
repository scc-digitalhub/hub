{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db437dfe",
   "metadata": {},
   "source": [
    "## 1. Initialize the project\n",
    "\n",
    "Create the working context: data download project if not created already. Project is a placeholder for the code, data, and management of the data operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22976efc-003a-4170-bcf0-6a33ac84e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitalhub as dh\n",
    "PROJECT_NAME = \"<YOUR_PROJECT_NAME>\"\n",
    "proj = dh.get_or_create_project(PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f207c763",
   "metadata": {},
   "source": [
    "Note: Make sure to replace <YOUR_PROJECT_NAME> with the actual name of your project before running the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ac45be",
   "metadata": {},
   "source": [
    "## 2. Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bc1125",
   "metadata": {},
   "source": [
    "Fetch the \"serve\" operation in the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3223f0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_OLlama_func = proj.get_function('llm-ollama-serve')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede40b55",
   "metadata": {},
   "source": [
    "Run the function with default configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c222c97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_run = llm_OLlama_func.run(\"serve\", wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa217ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = llm_run.refresh().status.service\n",
    "print(\"Service status:\", service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f8b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = llm_run.refresh().status.k8s.get(\"Model\")['status']\n",
    "print(\"Model status:\", status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e1e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_URL = llm_run.status.to_dict()[\"service\"][\"url\"]\n",
    "CHAT_MODEL = llm_run.status.to_dict()[\"openai\"][\"model\"]\n",
    "print(f\"service {CHAT_URL} with model {CHAT_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f98cd22",
   "metadata": {},
   "source": [
    "Note: using the Core Management UI, one can navigate to 'Runs' menu , select the corresponding 'run' instance and inspect the logs using 'Logs' tab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63fb2fb",
   "metadata": {},
   "source": [
    "## 3. Test the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de72a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name =llm_run.refresh().status.k8s.get(\"Model\").get(\"metadata\").get(\"name\")\n",
    "json_payload = {'model': CHAT_MODEL, 'prompt': 'Describe MLOps'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2467399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "result = llm_run.invoke(json=json_payload, url=service['url']+'/v1/completions').json()\n",
    "print(\"Response:\")\n",
    "pp.pprint(result)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6731bb57",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Response:\n",
    "{ 'choices': [ { 'finish_reason': 'stop',\n",
    "                 'index': 0,\n",
    "                 'text': 'MLOps (Machine Learning Operand Model) refers to the '\n",
    "                         'practice of turning machine learning models into '\n",
    "                         'deployable components that can be easily integrated '\n",
    "                         'into various applications, processes, and systems. '\n",
    "                         'The term \"operand\" implies the idea of operations or '\n",
    "                         'actions that can be performed on data.\\n'\n",
    "                         '\\n'\n",
    "                         'In the context of machine learning, MLOps involves a '\n",
    "                         'series of steps that transform a predictive model '\n",
    "                         'into a ready-to-apply solution:\\n'\n",
    "                         '\\n'\n",
    "                         '1. **Model definition**: Defining the algorithm, '\n",
    "                         'architecture, and hyperparameters of the machine '\n",
    "                         'learning model.\\n'\n",
    "                         '2. **Data preparation**: Collecting, preprocessing, '\n",
    "                         'and preparing the data required for training and '\n",
    "                         'testing the model.\\n'\n",
    "                         '3. **Model training**: Training the machine learning '\n",
    "                         'model using the prepared data.\\n'\n",
    "                         '4. **Model deployment**: Deploying the trained model '\n",
    "                         'into a production-ready environment, such as a cloud '\n",
    "                         'platform, on-premises infrastructure, or edge '\n",
    "                         'device.\\n'\n",
    "                         '5. **Model monitoring**: Monitoring the performance '\n",
    "                         'of the deployed model in real-time and making '\n",
    "                         'adjustments as needed.\\n'\n",
    "                         '6. **Model updates**: Updating the model with new '\n",
    "                         'data, techniques, or algorithms to improve its '\n",
    "                         'accuracy and performance.\\n'\n",
    "                         '\\n'\n",
    "                         'The benefits of MLOps include:\\n'\n",
    "                         '\\n'\n",
    "                         '* Improved collaboration: By breaking down machine '\n",
    "                         'learning into smaller, manageable tasks, teams can '\n",
    "                         'work together more efficiently.\\n'\n",
    "                         '* Faster development: MLOps enables rapid '\n",
    "                         'prototyping, testing, and deployment of models, '\n",
    "                         'reducing the time-to-market for new applications.\\n'\n",
    "                         '* Increased model transparency: MLOps data flows are '\n",
    "                         'easily configurable and visible, making it easier to '\n",
    "                         'understand how the model works.\\n'\n",
    "                         '*Reduced training time: Automated pipelines can '\n",
    "                         'automate many data preparation tasks, saving time '\n",
    "                         'and increasing productivity.\\n'\n",
    "                         '\\n'\n",
    "                         \"To implement MLOps effectively, you'll need:\\n\"\n",
    "                         '\\n'\n",
    "                         '* Good domain expertise in machine learning\\n'\n",
    "                         '* Tools like Jupyter Notebooks, TensorFlow, PyTorch, '\n",
    "                         'or scikit-learn\\n'\n",
    "                         '* Infrastructure for model deployment (e.g., Google '\n",
    "                         'Cloud AI Platform, Amazon SageMaker)\\n'\n",
    "                         '* Containerization technologies (e.g., Docker) to '\n",
    "                         'package models and their dependencies.\\n'\n",
    "                         '\\n'\n",
    "                         'By embracing MLOps principles, you can streamline '\n",
    "                         'your machine learning process, improve model '\n",
    "                         'performance, and accelerate time-to-market for new '\n",
    "                         'applications.'}],\n",
    "  'created': 1770724462,\n",
    "  'id': 'cmpl-766',\n",
    "  'model': 'model-b7f7d64f6b924b659845e9620405f86f',\n",
    "  'object': 'text_completion',\n",
    "  'system_fingerprint': 'fp_ollama',\n",
    "  'usage': {'completion_tokens': 431, 'prompt_tokens': 29, 'total_tokens': 460}}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
